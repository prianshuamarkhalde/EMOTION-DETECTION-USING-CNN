# EMOTION-DETECTION-USING-CNN

Project Overview
This project focuses on detecting human emotions from facial expressions using Convolutional Neural Networks (CNN). The model is trained on a dataset of labeled facial expressions, including emotions such as happy, sad, angry, surprised, neutral, and others. The CNN architecture learns features from facial images and classifies them into respective emotional categories.

Technologies Used
Python
TensorFlow / Keras
OpenCV
NumPy
Matplotlib

How It Works
Data Preprocessing: The images are resized and converted to grayscale for easier feature extraction.
Model Architecture: A CNN model with multiple convolutional and pooling layers is used to extract features from facial images.
Training: The model is trained using a labeled dataset, with accuracy and loss monitored throughout the process.
Emotion Prediction: After training, the model can predict emotions from new images in real-time.

Results
The trained model can predict emotions with a reasonable accuracy rate, depending on the quality and variety of the dataset used for training.
